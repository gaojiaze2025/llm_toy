import json
import re
import os
import requests
import time
from typing import Dict, Any, Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# 1. å®šä¹‰å·¥å…· (Tools)
def add_numbers(a: float, b: float) -> float:
    """å¯¹ä¸¤ä¸ªæ•°å­—åšåŠ æ³•è¿ç®—"""
    return a + b

# 2. å·¥å…·æ³¨å†Œè¡¨ (Tool Registry)
AVAILABLE_TOOLS = {
    "add_numbers": add_numbers,
}

# DeepSeek API é…ç½®
DEEPSEEK_CONFIG = {
    "api_key": os.getenv("DEEPSEEK_API_KEY"),
    "base_url": os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1"),
    "model": os.getenv("DEEPSEEK_MODEL", "deepseek-chat"),
    "temperature": 0.1,
    "max_tokens": 2000
}

# 3. çœŸå®çš„ DeepSeek API è°ƒç”¨å‡½æ•°ï¼ˆå¸¦é‡è¯•é€»è¾‘ï¼‰
def call_llm(history: list, system_prompt: str, max_retries: int = 3) -> str:
    """è°ƒç”¨ DeepSeek API å¹¶è¿”å›å“åº”æ–‡æœ¬"""
    
    # æ£€æŸ¥ API å¯†é’¥
    if not DEEPSEEK_CONFIG["api_key"]:
        raise ValueError("DeepSeek API key not found. Please set DEEPSEEK_API_KEY environment variable.")
    
    # å‡†å¤‡ API è¯·æ±‚æ•°æ®
    messages = []
    
    # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    
    # æ·»åŠ å†å²å¯¹è¯è®°å½•
    for msg in history[1:]:  # è·³è¿‡ç¬¬ä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»å•ç‹¬æ·»åŠ äº†
        if msg["role"] in ["user", "assistant", "system"]:
            messages.append({"role": msg["role"], "content": msg["content"]})
        elif msg["role"] == "tool":
            # å°†å·¥å…·å“åº”è½¬æ¢ä¸ºç”¨æˆ·æ¶ˆæ¯æ ¼å¼ï¼Œä»¥ä¾¿æ¨¡å‹ç†è§£
            messages.append({"role": "user", "content": msg["content"]})
    
    # API è¯·æ±‚å‚æ•°
    payload = {
        "model": DEEPSEEK_CONFIG["model"],
        "messages": messages,
        "temperature": DEEPSEEK_CONFIG["temperature"],
        "max_tokens": DEEPSEEK_CONFIG["max_tokens"],
        "stream": False
    }
    
    # API è¯·æ±‚å¤´
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_CONFIG['api_key']}"
    }
    
    # é‡è¯•é€»è¾‘
    for attempt in range(max_retries):
        try:
            # å‘é€ API è¯·æ±‚
            response = requests.post(
                f"{DEEPSEEK_CONFIG['base_url']}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            response.raise_for_status()
            
            # è§£æå“åº”æ•°æ®
            result = response.json()
            llm_response = result["choices"][0]["message"]["content"]
            
            return llm_response.strip()
            
        except requests.exceptions.RequestException as e:
            error_msg = f"API request failed (attempt {attempt + 1}/{max_retries}): {str(e)}"
            print(f"âŒ {error_msg}")
            
            if attempt == max_retries - 1:  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                return f"Error: {error_msg}"
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
            wait_time = 2 ** attempt
            print(f"â³ Retrying in {wait_time} seconds...")
            time.sleep(wait_time)
            
        except (KeyError, IndexError) as e:
            error_msg = f"Failed to parse API response: {str(e)}"
            print(f"âŒ {error_msg}")
            return f"Error: {error_msg}"
    
    return "Error: Maximum retry attempts exceeded."

# 4. Agent ä¸»å¾ªç¯å‡½æ•°
def run_agent_loop(initial_user_prompt: str, system_prompt: str, max_steps=5) -> str:
    
    # å†å²è®°å½•åˆå§‹åŒ–ï¼šåªæœ‰ System Prompt å’Œç”¨æˆ·æŒ‡ä»¤
    history = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": initial_user_prompt}
    ]
    
    # å¼€å§‹ Agent Loop
    for step in range(max_steps):
        print(f"\n--- ğŸ”„ Step {step + 1} ---")
        
        # 4a. æ„ŸçŸ¥ä¸æ€è€ƒ (Perception & Thinking)
        llm_response = call_llm(history, system_prompt)
        print(f"LLM Response:\n{llm_response}")
        
        # 4b. æ£€æŸ¥ Final Answer æ ‡ç­¾ (åˆ¤æ–­ç»ˆç»“)
        if "Final Answer:" in llm_response:
            final_answer = llm_response.split("Final Answer:", 1)[1].strip()
            return f"\nâœ… Agent Finished! Final Answer: {final_answer}"
        
        # 4c. æ£€æŸ¥ Action (åˆ¤æ–­å·¥å…·è°ƒç”¨)
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥æå–è¢« [ACTION_START] å’Œ [ACTION_END] åŒ…è£¹çš„ JSON
        action_match = re.search(r"\[ACTION_START\]\s*(\{.*?\})\s*\[ACTION_END\]", llm_response, re.DOTALL)
        
        if action_match:
            # æ‰¾åˆ° Actionï¼Œå°†å…¶æ·»åŠ åˆ°å†å²è®°å½•ä¸­
            action_json_str = action_match.group(1)
            history.append({"role": "assistant", "content": llm_response})
            
            # 4d. è§£æ Action å¹¶æ‰§è¡Œå·¥å…· (Action & Execution)
            try:
                action_dict = json.loads(action_json_str)
                tool_name = action_dict["tool"]
                tool_args = action_dict["args"]
                
                print(f"ğŸ› ï¸ Executing Tool: {tool_name} with args: {tool_args}")
                
                # åŠ¨æ€è°ƒç”¨å‡½æ•°
                if tool_name not in AVAILABLE_TOOLS:
                    raise ValueError(f"Tool {tool_name} not registered.")
                
                tool_function = AVAILABLE_TOOLS[tool_name]
                observation_result = tool_function(**tool_args)
                
                # 4e. æ ¼å¼åŒ– Observation (æ–°çš„æ„ŸçŸ¥)
                observation_message = f"Observation: {observation_result}"
                
                # 4f. æ›´æ–°å†å²è®°å½• (é—­ç¯)
                print(f"ğŸ“¢ Observation: {observation_result}")
                history.append({
                    "role": "tool", 
                    "content": observation_message
                })
                
            except (json.JSONDecodeError, KeyError, ValueError) as e:
                # é”™è¯¯å¤„ç†ï¼šå¦‚æœ LLM è¾“å‡ºçš„ JSON æœ‰è¯¯ï¼Œå°†é”™è¯¯ä½œä¸º Observation è¿”å›
                error_message = f"Tool Execution Error: {e}"
                print(f"âŒ {error_message}")
                history.append({"role": "tool", "content": f"Observation: {error_message}"})
        
        else:
            # LLM æ²¡æœ‰ç»™å‡º Final Answer ä¹Ÿæ²¡æœ‰ç»™å‡º Actionï¼Œè§†ä¸ºé”™è¯¯æˆ–ä¸­é—´æ–‡æœ¬
            print("ğŸ›‘ Error: LLM output is ambiguous. Stopping.")
            return "âŒ Agent failed to produce a valid action or final answer."

    return "âŒ Max steps reached without a final answer."

# --- è¿è¡Œç¤ºä¾‹ ---

SYSTEM_PROMPT = """
ä½ æ˜¯æ™ºèƒ½è®¡ç®—å™¨Agentã€‚ä½ çš„ç›®æ ‡æ˜¯æ ¹æ®ç”¨æˆ·æŒ‡ä»¤å®Œæˆæ•°å­¦è®¡ç®—ã€‚
ä½ å¿…é¡»éµå¾ª ReAct æ¡†æ¶ï¼š

## è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1. **æ€è€ƒ (Thought)**: æè¿°ä½ çš„æ¨ç†è¿‡ç¨‹ã€è®¡åˆ’å’Œè¦ä½¿ç”¨çš„å·¥å…·ã€‚
2. **è¡ŒåŠ¨ (Action)**: å¦‚æœéœ€è¦å·¥å…·ï¼Œå¿…é¡»è¾“å‡º JSON æ ¼å¼ï¼Œå¹¶ä¸¥æ ¼å°è£…åœ¨ [ACTION_START] å’Œ [ACTION_END] æ ‡ç­¾å†…ã€‚
3. **è§‚å¯Ÿ (Observation)**: è¿™æ˜¯å·¥å…·è¿”å›çš„ç»“æœï¼Œä½ å¿…é¡»åœ¨ä¸‹ä¸€è½® Thought ä¸­åˆ©ç”¨å®ƒã€‚

## é‡è¦è§„åˆ™ï¼š
- å½“ä½ ç¡®å®šä»»åŠ¡å·²å®Œæˆæ—¶ï¼Œå¿…é¡»ä»¥ 'Final Answer:' å¼€å¤´ç»™å‡ºæœ€ç»ˆç»“æœã€‚
- æ¯æ¬¡å“åº”å¿…é¡»åŒ…å« Thought éƒ¨åˆ†
- å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡º Action
- ä¸è¦åœ¨ä¸€ä¸ªå“åº”ä¸­åŒæ—¶åŒ…å« Action å’Œ Final Answer

## å¯ç”¨å·¥å…·ï¼š
- {"tool": "add_numbers", "description": "å¯¹ä¸¤ä¸ªæ•°å­—åšåŠ æ³•è¿ç®—", "args": {"a": float, "b": float}}

## ç¤ºä¾‹å“åº”æ ¼å¼ï¼š
```
Thought: æˆ‘éœ€è¦è®¡ç®—ä¸¤ä¸ªæ•°å­—çš„å’Œï¼Œæˆ‘å°†ä½¿ç”¨ add_numbers å·¥å…·ã€‚
[ACTION_START]
{"tool": "add_numbers", "args": {"a": 123, "b": 456}}
[ACTION_END]
```

æˆ–

```
Thought: æˆ‘å·²ç»è·å¾—äº†è®¡ç®—ç»“æœï¼Œç°åœ¨å¯ä»¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
Final Answer: 123 åŠ ä¸Š 456 çš„ç»“æœæ˜¯ 579ã€‚
```
"""

user_input = "è®¡ç®— 123 åŠ ä¸Š 456 å‡å» 789 çš„ç»“æœæ˜¯å¤šå°‘ï¼Ÿ"
final_result = run_agent_loop(user_input, SYSTEM_PROMPT)
print(final_result)